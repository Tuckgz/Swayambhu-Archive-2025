{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omw5F2T-haJG"
      },
      "source": [
        "**Recommended:**<br/>\n",
        "Use a device with a dedicated Graphics card, everything will be much faster.\n",
        "\n",
        "create a virtual environment to run whisper.<br/>\n",
        "run the following in a terminal:<br/>\n",
        "```python -m venv whisper-env```\n",
        "\n",
        "To access virtual environment, run the following in a terminal.\n",
        "\n",
        "**on Windows:**<br/>\n",
        "```.\\whisper-env\\Scripts\\activate```\n",
        "\n",
        "**on Mac:**<br/>\n",
        "```source whisper-env/bin/activate```\n",
        "\n",
        "**on Google Colab:**\n",
        "already set up, very simple."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4y-Yns5haJI"
      },
      "source": [
        "Check to make sure the notebook is using the environment. The file path should show something with ```whisper-env``` if correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFpyOQi-haJJ"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "print(sys.executable)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If using colab, run below. Otherwise, find correct installs for ffmpeg."
      ],
      "metadata": {
        "id": "qi78n2hU-M8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y ffmpeg"
      ],
      "metadata": {
        "id": "Y_90xr7dhkrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gytm5ggohaJK"
      },
      "source": [
        "Install required libraries for running whisper locally. These steps may be different for Mac and Windows users.\n",
        "\n",
        "**for Windows:**<br/>\n",
        "find and install ffmpeg from the internet. This should be an executable, so it will automatically set up in your program files.\n",
        "\n",
        "Next, pip install the libraries into your virtual environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ak1aziQKhaJK"
      },
      "outputs": [],
      "source": [
        "%pip install openai-whisper\n",
        "%pip install ffmpeg\n",
        "%pip install pytube\n",
        "%pip install pydub\n",
        "%pip install yt-dlp\n",
        "%pip install googletrans==4.0.0-rc1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLlqJZTEhaJL"
      },
      "source": [
        "PyTorch and companions are required. However, if you want to use a graphics card for faster processing, there are some additional steps.\n",
        "\n",
        "**for Mac:**<br/>\n",
        "You can use Metal if it's a silicon chip. This is experimental at the time of writing this document (2025).<br/>\n",
        "```pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/mps```\n",
        "\n",
        "**for Windows:**<br/>\n",
        "You'll need to first install the CUDA toolkit from Nvidia's website. This comes with an install wizard and goes to Program Files.<br/>\n",
        "You also should use CudNN from the website as well. This is a zip file, which needs to be unpacked and manually moved to the CUDA program files.<br/>\n",
        "Just match the name of the folders, and copy over all of the zip files contents to the CUDA folders respectively.\n",
        "\n",
        "finally, here's the pip for nightly.<br/>\n",
        "```pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126```\n",
        "\n",
        "**for Google Colab:**<br/>\n",
        "This should again be already set up, skip the next code below.\n",
        "\n",
        "Uncomment the lines below for your specific use case:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jD0tWL1haJM"
      },
      "outputs": [],
      "source": [
        "# General case, no GPU\n",
        "# %pip install torch torchvision torchaudio\n",
        "\n",
        "# Mac using Metal\n",
        "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/mps\n",
        "\n",
        "# Windows using CUDA 12.6+ (modify /cu126 for specific requirements)\n",
        "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwtQCO2EhaJN"
      },
      "source": [
        "Check to verify CUDA is reachable, and GPU is registered properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGFxMcGghaJO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(torch.__version__)  # Ensure it's the latest nightly build\n",
        "print(torch.cuda.is_available())  # Should return True if CUDA is available\n",
        "print(torch.version.cuda)\n",
        "print(torch.cuda.get_device_name(0))  # Should show your GPU model\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI2xJkOOhaJR"
      },
      "source": [
        "This is the best accuracy I've gotten in transcription. The result should be the non-translated transcription file with timestamps."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import os\n",
        "import subprocess\n",
        "from pydub import AudioSegment\n",
        "from datetime import datetime\n",
        "\n",
        "# Set ffmpeg path explicitly (adjust if necessary)\n",
        "os.environ[\"FFMPEG_BINARY\"] = \"C:/ProgramData/chocolatey/bin/ffmpeg.exe\"\n",
        "\n",
        "# Check ffmpeg availability\n",
        "subprocess.run(['ffmpeg', '-version'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "# Ensure required directories exist\n",
        "os.makedirs(\"audio_files\", exist_ok=True)\n",
        "os.makedirs(\"transcripts\", exist_ok=True)\n",
        "\n",
        "# Generate unique timestamp\n",
        "def get_timestamp():\n",
        "    return datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Convert seconds to minutes:seconds format\n",
        "def format_timestamp(seconds):\n",
        "    minutes = int(seconds // 60)\n",
        "    remaining_seconds = int(seconds % 60)\n",
        "    return f\"{minutes}m{remaining_seconds}s\"\n",
        "\n",
        "# Transcribe Audio using Whisper (no translation)\n",
        "def transcribe_audio(audio_path):\n",
        "    model = whisper.load_model(\"large\")\n",
        "    print(f\"Transcribing {audio_path}...\")\n",
        "\n",
        "    # Transcribe using Whisper (task = \"transcribe\")\n",
        "    result = model.transcribe(audio_path, word_timestamps=True, verbose=True)\n",
        "    detected_language = result[\"language\"]\n",
        "    print(f\"Detected language: {detected_language}\")\n",
        "\n",
        "    # Collect the transcription with timestamps\n",
        "    segments = []\n",
        "    for segment in result[\"segments\"]:\n",
        "        start_time = segment[\"start\"]\n",
        "        end_time = segment[\"end\"]\n",
        "        text = segment['text']\n",
        "        formatted_start_time = format_timestamp(start_time)\n",
        "        formatted_end_time = format_timestamp(end_time)\n",
        "        segments.append(f\"[{formatted_start_time} - {formatted_end_time}]: {text}\")\n",
        "\n",
        "    # Combine all segments into a single string\n",
        "    full_transcription = \"\\n\".join(segments)\n",
        "    return full_transcription\n",
        "\n",
        "# Save the non-translated transcription with timestamps\n",
        "def save_combined_transcription_without_translation(full_transcription):\n",
        "    timestamp = get_timestamp()\n",
        "    combined_file_path = f\"transcripts/combined_transcription_{timestamp}.txt\"\n",
        "\n",
        "    with open(combined_file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(full_transcription)\n",
        "\n",
        "    print(f\"Saved combined transcription to {combined_file_path}\")\n",
        "\n",
        "import yt_dlp as youtube_dl\n",
        "\n",
        "# Download YouTube Video Audio using yt-dlp\n",
        "def download_audio(youtube_url, output_path=\"audio_files/audio.mp4\"):\n",
        "    print(\"Downloading video...\")\n",
        "    ydl_opts = {'format': 'bestaudio/best', 'outtmpl': output_path}\n",
        "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([youtube_url])\n",
        "    print(\"Download complete!\")\n",
        "\n",
        "# Main function (for testing or production)\n",
        "def main(input_source):\n",
        "    # This will hold the full transcription with timestamps\n",
        "    full_transcription = \"\"\n",
        "    audio_path = None  # This will store the final audio file to process\n",
        "\n",
        "    # Check if input is a YouTube URL or a local file\n",
        "    if input_source.startswith(\"http\"):\n",
        "        print(\"Downloading audio from YouTube...\")\n",
        "        audio_path = f\"audio_files/audio_{get_timestamp()}.mp4\"\n",
        "        try:\n",
        "            download_audio(input_source, audio_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading YouTube audio: {e}\")\n",
        "            return\n",
        "    else:\n",
        "        if not os.path.exists(input_source):\n",
        "            print(f\"Error: The file '{input_source}' does not exist.\")\n",
        "            return\n",
        "        audio_path = input_source\n",
        "\n",
        "    # Transcribe the audio in a single go using Whisper\n",
        "    try:\n",
        "        full_transcription = transcribe_audio(audio_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error transcribing {audio_path}: {e}\")\n",
        "        return\n",
        "\n",
        "    # Save the combined transcription with timestamps (non-translated)\n",
        "    if full_transcription:\n",
        "        save_combined_transcription_without_translation(full_transcription)\n",
        "    else:\n",
        "        print(\"No transcription was generated.\")\n",
        "\n",
        "    # Clean up downloaded YouTube audio if applicable\n",
        "    if input_source.startswith(\"http\"):\n",
        "        try:\n",
        "            os.remove(audio_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not delete {audio_path}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    user_input = input(\"Enter YouTube link or local audio file path: \").strip()\n",
        "    main(user_input)\n"
      ],
      "metadata": {
        "id": "sWFLvcCctvl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For translation, batch translation of the full transcription file seems to be most accurate. Unfortunately most accurate methods require manual entry or are not free, finding both in one API has yet to happen.\n",
        "\n",
        "My low tech solution is to copy and paste the contents of the file in either an AI like ChatGPT or DeepSeek, or use Google Translate.\n",
        "\n",
        "ChatGPT and DeepSeek have proven more accurate so far, though may present challenges with larger files."
      ],
      "metadata": {
        "id": "G5njmhMl9I-l"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}